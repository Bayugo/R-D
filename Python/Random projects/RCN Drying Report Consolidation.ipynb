{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ee25ba4-891e-4485-b2ab-74ae4a292f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2498f0b7-609e-4bbb-8639-fb170f055966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SUMMARY', '2025-QUALITY REP', 'FUNDING', 'SAMPA-PURCHASES', 'SAMPA-DRYING', 'SAMPA-DISPATCHES ', 'SAMPA W.H', 'NKRANKWANTA-PURCHASES', 'NKRANKWANTA-DRYING', 'NKRANKWANTA-DISPATCHES', 'NKRANKWANTA W.H', 'DROBO-PURCHASES', 'DROBO-DRYING', 'DROBO-DISPATCHES', 'DROBO W.H', 'WENCHI-PURCHASES', 'WENCHI-DRYING', 'WENCHI-DISPATCHES', 'WENCHI W.H', 'TECHIMAN-PURCHASES', 'TECHIMAN-DRYING', 'TECHIMAN-DISPATCHES', 'TECHIMAN W.H', 'SAWLA-PURCHASES', 'SAWLA-DRYING', 'SAWLA-DISPATCHES', 'SAWLA W.H ', 'LUC DISP', 'EX-TEMA', 'TOTALS', 'Comparisons']\n"
     ]
    }
   ],
   "source": [
    "xls_drying = pd.ExcelFile('GHANA ORIGIN REP.xlsx')\n",
    "print(xls_drying.sheet_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "996391c9-42c6-4fee-9381-d95e0042f373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected drying Sheets:\n",
      "SAMPA-DRYING\n",
      "NKRANKWANTA-DRYING\n",
      "DROBO-DRYING\n",
      "WENCHI-DRYING\n",
      "TECHIMAN-DRYING\n",
      "SAWLA-DRYING\n"
     ]
    }
   ],
   "source": [
    "# List of all sheets related to \"Purchases\"\n",
    "drying_sheets = [\n",
    "    'SAMPA-DRYING',\n",
    "    'NKRANKWANTA-DRYING',\n",
    "    'DROBO-DRYING',\n",
    "    'WENCHI-DRYING',\n",
    "    'TECHIMAN-DRYING',\n",
    "    'SAWLA-DRYING'\n",
    "]\n",
    "\n",
    "# Selecting the sheets using pandas\n",
    "selected_sheets = {sheet: pd.read_excel(xls_drying, sheet) for sheet in drying_sheets}\n",
    "\n",
    "# Display the names of the selected sheets\n",
    "print(\"Selected drying Sheets:\")\n",
    "for sheet_name in selected_sheets:\n",
    "    print(sheet_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21efee11-3007-420a-8616-ed2a6a70b580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sampa DataFrame shape: (698, 14)\n",
      "Nkrankwanta DataFrame shape: (698, 14)\n",
      "Drobo DataFrame shape: (698, 14)\n",
      "Wenchi DataFrame shape: (536, 14)\n",
      "Techiman DataFrame shape: (532, 15)\n",
      "Sawla DataFrame shape: (532, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>GRN #</th>\n",
       "      <th># OF BAGS</th>\n",
       "      <th>NET WEIGHT</th>\n",
       "      <th>ARRIV KOR</th>\n",
       "      <th>MOISTURE %</th>\n",
       "      <th>DATE.1</th>\n",
       "      <th># OF BAGS.1</th>\n",
       "      <th>NET WEIGHT.1</th>\n",
       "      <th>KOR AFTER DRYING</th>\n",
       "      <th>MOISTURE %.1</th>\n",
       "      <th>WEIGHT LOSS(Kg)</th>\n",
       "      <th>LOSS %AGE</th>\n",
       "      <th>Pickings-Kgs</th>\n",
       "      <th>Unnamed: 14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-01-13</td>\n",
       "      <td>151.0</td>\n",
       "      <td>24</td>\n",
       "      <td>2036.0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.9</td>\n",
       "      <td>14-01-2025</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1999.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.3</td>\n",
       "      <td>36.8</td>\n",
       "      <td>1.807466</td>\n",
       "      <td>NaN</td>\n",
       "      <td>212.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-01-13</td>\n",
       "      <td>152.0</td>\n",
       "      <td>23</td>\n",
       "      <td>1957.0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.9</td>\n",
       "      <td>14-01-2025</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1926.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.6</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1.584057</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        DATE  GRN #  # OF BAGS  NET WEIGHT  ARRIV KOR  MOISTURE %      DATE.1  \\\n",
       "0 2025-01-13  151.0         24      2036.0          0        11.9  14-01-2025   \n",
       "1 2025-01-13  152.0         23      1957.0          0        11.9  14-01-2025   \n",
       "\n",
       "   # OF BAGS.1  NET WEIGHT.1  KOR AFTER DRYING  MOISTURE %.1  WEIGHT LOSS(Kg)  \\\n",
       "0         24.0        1999.2               NaN           9.3             36.8   \n",
       "1         24.0        1926.0               NaN           9.6             31.0   \n",
       "\n",
       "   LOSS %AGE  Pickings-Kgs  Unnamed: 14  \n",
       "0   1.807466           NaN        212.0  \n",
       "1   1.584057           NaN         69.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert the drying sheets into separate DataFrames\n",
    "sampa_df = pd.read_excel(xls_drying, sheet_name='SAMPA-DRYING', header=2)\n",
    "nkrankwanta_df = pd.read_excel(xls_drying, sheet_name='NKRANKWANTA-DRYING', header=2)\n",
    "drobo_df = pd.read_excel(xls_drying, sheet_name='DROBO-DRYING', header=2)\n",
    "wenchi_df = pd.read_excel(xls_drying, sheet_name='WENCHI-DRYING', header=2)\n",
    "techiman_df = pd.read_excel(xls_drying, sheet_name='TECHIMAN-DRYING', header=2)\n",
    "sawla_df = pd.read_excel(xls_drying, sheet_name='SAWLA-DRYING', header=2)\n",
    "\n",
    "# Display the shape of each DataFrame for verification\n",
    "print(f\"Sampa DataFrame shape: {sampa_df.shape}\")\n",
    "print(f\"Nkrankwanta DataFrame shape: {nkrankwanta_df.shape}\")\n",
    "print(f\"Drobo DataFrame shape: {drobo_df.shape}\")\n",
    "print(f\"Wenchi DataFrame shape: {wenchi_df.shape}\")\n",
    "print(f\"Techiman DataFrame shape: {techiman_df.shape}\")\n",
    "print(f\"Sawla DataFrame shape: {sawla_df.shape}\")\n",
    "techiman_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d01a9429-e6c1-4d63-85e0-4532598882b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        DATE     DATE.1\n",
      "0 2025-01-30 2025-01-30\n",
      "1        NaT        NaT\n",
      "2        NaT        NaT\n",
      "3        NaT        NaT\n",
      "4        NaT        NaT\n",
      "   DATE  DATE.1\n",
      "0   NaN     NaN\n",
      "1   NaN     NaN\n",
      "2   NaN     NaN\n",
      "3   NaN     NaN\n",
      "4   NaN     NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abayugo01\\AppData\\Local\\Temp\\ipykernel_5036\\1186427924.py:3: UserWarning: Parsing dates in %d-%m-%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  invalid_date_rows = df[df['DATE'].apply(pd.to_datetime, errors='coerce').isna()]\n",
      "C:\\Users\\abayugo01\\AppData\\Local\\Temp\\ipykernel_5036\\1186427924.py:6: UserWarning: Parsing dates in %d-%m-%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df['DATE'] = df['DATE'].apply(lambda x: pd.to_datetime(x, errors='coerce') if isinstance(x, str) else x)\n",
      "C:\\Users\\abayugo01\\AppData\\Local\\Temp\\ipykernel_5036\\1186427924.py:7: UserWarning: Parsing dates in %d-%m-%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df['DATE.1'] = df['DATE.1'].apply(lambda x: pd.to_datetime(x, errors='coerce') if isinstance(x, str) else x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        DATE     DATE.1\n",
      "0 2025-01-16 2025-01-16\n",
      "1 2025-01-17 2025-01-17\n",
      "2 2025-01-22 2025-01-22\n",
      "3 2025-01-24 2025-01-24\n",
      "4 2025-01-24 2025-01-24\n",
      "        DATE     DATE.1\n",
      "0 2025-01-14 2025-01-21\n",
      "1 2025-01-14 2025-01-22\n",
      "2 2025-01-15 2025-01-22\n",
      "3 2025-01-15 2025-01-21\n",
      "4 2025-01-16 2025-01-21\n",
      "        DATE     DATE.1\n",
      "0 2025-01-13 2025-01-14\n",
      "1 2025-01-13 2025-01-14\n",
      "2 2025-01-14 2025-01-15\n",
      "3 2025-01-14 2025-01-15\n",
      "4 2025-01-15 2025-01-16\n",
      "   DATE  DATE.1\n",
      "0   NaN     NaN\n",
      "1   NaN     NaN\n",
      "2   NaN     NaN\n",
      "3   NaN     NaN\n",
      "4   NaN     NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abayugo01\\AppData\\Local\\Temp\\ipykernel_5036\\1186427924.py:7: UserWarning: Parsing dates in %d-%m-%Y format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  df['DATE.1'] = df['DATE.1'].apply(lambda x: pd.to_datetime(x, errors='coerce') if isinstance(x, str) else x)\n"
     ]
    }
   ],
   "source": [
    "# Check for rows where DATE or DATE.1 might have invalid date strings\n",
    "for df in [sampa_df, nkrankwanta_df, drobo_df, wenchi_df, techiman_df, sawla_df]:\n",
    "    invalid_date_rows = df[df['DATE'].apply(pd.to_datetime, errors='coerce').isna()]\n",
    "    #print(invalid_date_rows[['DATE', 'DATE.1']])\n",
    "    # Ensure all dates are in the expected format (e.g., 'YYYY-MM-DD')\n",
    "    df['DATE'] = df['DATE'].apply(lambda x: pd.to_datetime(x, errors='coerce') if isinstance(x, str) else x)\n",
    "    df['DATE.1'] = df['DATE.1'].apply(lambda x: pd.to_datetime(x, errors='coerce') if isinstance(x, str) else x)\n",
    "    print(df[['DATE', 'DATE.1']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b47c19a6-2605-470b-8a38-7d64319b8c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated DataFrames:\n",
      "sampa_df - Shape: (1, 14)\n",
      "nkrankwanta_df - Shape: (0, 14)\n",
      "drobo_df - Shape: (13, 14)\n",
      "wenchi_df - Shape: (20, 14)\n",
      "techiman_df - Shape: (26, 14)\n",
      "sawla_df - Shape: (0, 14)\n"
     ]
    }
   ],
   "source": [
    "# 0. Remove 'Unnamed: 14' column from techiman_df\n",
    "techiman_df.drop(columns=['Unnamed: 14'], inplace=True)\n",
    "\n",
    "# 1. Convert DATE and DATE.1 columns to datetime\n",
    "#for df in [sampa_df, nkrankwanta_df, drobo_df, wenchi_df, techiman_df, sawla_df]:\n",
    "#    df['DATE'] = pd.to_datetime(df['DATE'], errors='coerce')\n",
    "#    df['DATE.1'] = pd.to_datetime(df['DATE.1'], errors='coerce')\n",
    "\n",
    "# 2. Sort by DATE column (from oldest to newest)\n",
    "for df in [sampa_df, nkrankwanta_df, drobo_df, wenchi_df, techiman_df, sawla_df]:\n",
    "    df.sort_values(by='DATE', ascending=True, inplace=True)\n",
    "\n",
    "# 3. Remove rows where DATE is N/A\n",
    "for df in [sampa_df, nkrankwanta_df, drobo_df, wenchi_df, techiman_df, sawla_df]:\n",
    "    df.dropna(subset=['DATE'], inplace=True)\n",
    "\n",
    "# 4. Rename columns that have '1' at the end to 'AFTER DRYING'\n",
    "rename_dict = {\n",
    "    '# OF BAGS.1': '# OF BAGS AFTER DRYING',\n",
    "    'NET WEIGHT.1': 'NET WEIGHT AFTER DRYING',\n",
    "    'MOISTURE %.1': 'MOISTURE % AFTER DRYING',\n",
    "    'DATE.1': 'DATE AFTER DRYING',\n",
    "    'KOR AFTER DRYING': 'KOR AFTER DRYING'\n",
    "}\n",
    "\n",
    "for df in [sampa_df, nkrankwanta_df, drobo_df, wenchi_df, techiman_df, sawla_df]:\n",
    "    df.rename(columns=rename_dict, inplace=True)\n",
    "\n",
    "# Display the updated DataFrames to confirm the changes\n",
    "print(\"Updated DataFrames:\")\n",
    "for df_name in ['sampa_df', 'nkrankwanta_df', 'drobo_df', 'wenchi_df', 'techiman_df', 'sawla_df']:\n",
    "    df = globals()[df_name]\n",
    "    print(f\"{df_name} - Shape: {df.shape}\")\n",
    "    #print(df.head(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fe22936-db27-4695-98f4-4fd16ff4c3af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abayugo01\\AppData\\Local\\Temp\\ipykernel_5036\\261561821.py:28: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  drying_df = pd.concat([df[common_columns_list] for df in [sampa_df, nkrankwanta_df, drobo_df, wenchi_df, techiman_df, sawla_df]], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 14)\n"
     ]
    }
   ],
   "source": [
    "# Add Station column for each DataFrame\n",
    "sampa_df['Station'] = 'Sampa'\n",
    "nkrankwanta_df['Station'] = 'Nkrankwanta'\n",
    "drobo_df['Station'] = 'Drobo'\n",
    "wenchi_df['Station'] = 'Wenchi'\n",
    "techiman_df['Station'] = 'Techiman'\n",
    "sawla_df['Station'] = 'Sawla'\n",
    "\n",
    "# Get the column names from each DataFrame\n",
    "sampa_columns = set(sampa_df.columns)\n",
    "nkrankwanta_columns = set(nkrankwanta_df.columns)\n",
    "drobo_columns = set(drobo_df.columns)\n",
    "wenchi_columns = set(wenchi_df.columns)\n",
    "techiman_columns = set(techiman_df.columns)\n",
    "sawla_columns = set(sawla_df.columns)\n",
    "\n",
    "# Find the intersection (common columns) across all the DataFrames\n",
    "common_columns = sampa_columns.intersection(nkrankwanta_columns, drobo_columns, wenchi_columns, techiman_columns, sawla_columns)\n",
    "\n",
    "# Convert common_columns to a list\n",
    "common_columns_list = list(common_columns)\n",
    "\n",
    "# Display the common columns\n",
    "#print(\"Common columns across all drying sheets:\")\n",
    "#print(common_columns_list)\n",
    "\n",
    "# Append the DataFrames with only common columns\n",
    "drying_df = pd.concat([df[common_columns_list] for df in [sampa_df, nkrankwanta_df, drobo_df, wenchi_df, techiman_df, sawla_df]], ignore_index=True)\n",
    "\n",
    "# Define the correct order of columns\n",
    "column_order = ['Station', 'DATE', 'GRN #', '# OF BAGS', 'NET WEIGHT', 'ARRIV KOR', 'MOISTURE %', \n",
    "                'DATE AFTER DRYING', '# OF BAGS AFTER DRYING', 'NET WEIGHT AFTER DRYING', 'KOR AFTER DRYING', \n",
    "                'MOISTURE % AFTER DRYING', 'WEIGHT LOSS(Kg)', 'LOSS %AGE']\n",
    "\n",
    "# Rearrange the columns in the specified order\n",
    "drying_df = drying_df[column_order]\n",
    "\n",
    "# Sort by the 'DATE' column from oldest to newest\n",
    "drying_df.sort_values(by='DATE', ascending=True, inplace=True)\n",
    "\n",
    "# Display the updated DataFrame to confirm the changes\n",
    "# Display the shape of the combined DataFrame\n",
    "print(drying_df.shape)\n",
    "drying_df.head(2)\n",
    "# Save the final combined DataFrame to an Excel file\n",
    "drying_df.to_excel('Ghana RCN Drying.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f4e33a-833b-48e8-9653-22db0c3ba3f7",
   "metadata": {},
   "source": [
    "## Summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e49e3c7e-d019-4460-8aea-697ac91f0415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Summary:\n",
      "+-------------------------------------------+--------------------+\n",
      "|                  Metric                   |       Value        |\n",
      "+-------------------------------------------+--------------------+\n",
      "|      Total Net Weight Before Drying       |     268251.75      |\n",
      "|       Total Net Weight After Drying       |      262299.3      |\n",
      "| Total Net Weight Before Drying (in 1000s) |     268.25175      |\n",
      "| Total Net Weight After Drying (in 1000s)  |      262.2993      |\n",
      "|         Average KOR Before Drying         | 10.763499999999999 |\n",
      "|         Average KOR After Drying          | 50.05692307692307  |\n",
      "|      Average Moisture Before Drying       | 11.783333333333335 |\n",
      "|       Average Moisture After Drying       |  9.28135593220339  |\n",
      "|         Total Weight Loss or Gain         |      5952.45       |\n",
      "|    Average Cycle Time in Drying (Days)    | 0.9833333333333333 |\n",
      "+-------------------------------------------+--------------------+\n",
      "\n",
      "Monthly Summary:\n",
      "+---------+----------------------+---------------------+-------------------------+------------------------+--------------------+-------------------+---------------------+--------------------+---------------------------+--------------------+\n",
      "|  DATE   | total_net_wgt_before | total_net_wgt_after | total_net_wgt_before_kg | total_net_wgt_after_kg |   avg_kor_before   |   avg_kor_after   | avg_moisture_before | avg_moisture_after | total_weight_loss_or_gain |   avg_cycle_time   |\n",
      "+---------+----------------------+---------------------+-------------------------+------------------------+--------------------+-------------------+---------------------+--------------------+---------------------------+--------------------+\n",
      "| 2025-01 |      268251.75       |      262299.3       |        268.25175        |        262.2993        | 10.763499999999999 | 50.05692307692308 | 11.783333333333333  |  9.28135593220339  |     5952.449999999999     | 0.9833333333333333 |\n",
      "+---------+----------------------+---------------------+-------------------------+------------------------+--------------------+-------------------+---------------------+--------------------+---------------------------+--------------------+\n",
      "\n",
      "Station Summary:\n",
      "+----------+----------------------+---------------------+-------------------------+------------------------+--------------------+-------------------+---------------------+--------------------+---------------------------+---------------------+\n",
      "| Station  | total_net_wgt_before | total_net_wgt_after | total_net_wgt_before_kg | total_net_wgt_after_kg |   avg_kor_before   |   avg_kor_after   | avg_moisture_before | avg_moisture_after | total_weight_loss_or_gain |   avg_cycle_time    |\n",
      "+----------+----------------------+---------------------+-------------------------+------------------------+--------------------+-------------------+---------------------+--------------------+---------------------------+---------------------+\n",
      "|  Drobo   |       30292.0        |       29523.0       |         30.292          |         29.523         | 49.677692307692304 | 50.05692307692308 |  12.36923076923077  | 9.615384615384615  |           769.0           | 0.3076923076923077  |\n",
      "|  Sampa   |        6280.0        |       6080.0        |          6.28           |          6.08          |        0.0         |        nan        |         0.0         |        nan         |           200.0           |         0.0         |\n",
      "| Techiman |       96123.05       |       95178.3       |    96.12304999999999    |   95.17830000000001    |        0.0         |        nan        |  11.03076923076923  |        9.2         |          944.75           | 0.38461538461538464 |\n",
      "|  Wenchi  |  135556.69999999998  |      131518.0       |        135.5567         |        131.518         |        0.0         |        nan        | 12.969999999999999  |        9.17        |     4038.699999999999     |        2.25         |\n",
      "+----------+----------------------+---------------------+-------------------------+------------------------+--------------------+-------------------+---------------------+--------------------+---------------------------+---------------------+\n",
      "\n",
      "Today's Drying Summary:\n",
      "+--------------------------------+-------------------------------+---------------------------+--------------------------+--------------------------------+-------------------------------+---------------------------+---------------------------+\n",
      "| Total Net Weight Before Drying | Total Net Weight After Drying | Average KOR Before Drying | Average KOR After Drying | Average Moisture Before Drying | Average Moisture After Drying | Total Weight Loss or Gain | Average Cycle Time (Days) |\n",
      "+--------------------------------+-------------------------------+---------------------------+--------------------------+--------------------------------+-------------------------------+---------------------------+---------------------------+\n",
      "|              0.0               |              0.0              |            nan            |           nan            |              nan               |              nan              |            0.0            |            nan            |\n",
      "+--------------------------------+-------------------------------+---------------------------+--------------------------+--------------------------------+-------------------------------+---------------------------+---------------------------+\n"
     ]
    }
   ],
   "source": [
    "i# 1. Total Net Weight Before and After Drying\n",
    "total_net_wgt_before = drying_df['NET WEIGHT'].sum()\n",
    "total_net_wgt_after = drying_df['NET WEIGHT AFTER DRYING'].sum()\n",
    "\n",
    "# 2. Total Net Weight Before and After Drying (in 1000s)\n",
    "total_net_wgt_before_kg = total_net_wgt_before / 1000\n",
    "total_net_wgt_after_kg = total_net_wgt_after / 1000\n",
    "\n",
    "# 3. Average KOR Before and After Drying\n",
    "avg_kor_before = drying_df['ARRIV KOR'].mean()\n",
    "avg_kor_after = drying_df['KOR AFTER DRYING'].mean()\n",
    "\n",
    "# 4. Average Moisture Before and After Drying\n",
    "avg_moisture_before = drying_df['MOISTURE %'].mean()\n",
    "avg_moisture_after = drying_df['MOISTURE % AFTER DRYING'].mean()\n",
    "\n",
    "# 5. Weight Loss or Gain\n",
    "drying_df['WEIGHT LOSS OR GAIN'] = drying_df['NET WEIGHT'] - drying_df['NET WEIGHT AFTER DRYING']\n",
    "total_weight_loss_or_gain = drying_df['WEIGHT LOSS OR GAIN'].sum()\n",
    "\n",
    "# 6. Average Cycle Time in Drying\n",
    "# Assuming that the cycle time is calculated as the difference between DATE AFTER DRYING and DATE\n",
    "drying_df['CYCLE TIME (DAYS)'] = (drying_df['DATE AFTER DRYING'] - drying_df['DATE']).dt.days\n",
    "avg_cycle_time = drying_df['CYCLE TIME (DAYS)'].mean()\n",
    "\n",
    "# Tabulate overall summary\n",
    "overall_summary = [\n",
    "    [\"Total Net Weight Before Drying\", total_net_wgt_before],\n",
    "    [\"Total Net Weight After Drying\", total_net_wgt_after],\n",
    "    [\"Total Net Weight Before Drying (in 1000s)\", total_net_wgt_before_kg],\n",
    "    [\"Total Net Weight After Drying (in 1000s)\", total_net_wgt_after_kg],\n",
    "    [\"Average KOR Before Drying\", avg_kor_before],\n",
    "    [\"Average KOR After Drying\", avg_kor_after],\n",
    "    [\"Average Moisture Before Drying\", avg_moisture_before],\n",
    "    [\"Average Moisture After Drying\", avg_moisture_after],\n",
    "    [\"Total Weight Loss or Gain\", total_weight_loss_or_gain],\n",
    "    [\"Average Cycle Time in Drying (Days)\", avg_cycle_time]\n",
    "]\n",
    "\n",
    "print(\"\\nOverall Summary:\")\n",
    "print(tabulate(overall_summary, headers=[\"Metric\", \"Value\"], tablefmt=\"pretty\"))\n",
    "\n",
    "# Monthly Summary\n",
    "monthly_summary = drying_df.groupby(drying_df['DATE'].dt.to_period('M')).agg(\n",
    "    total_net_wgt_before=('NET WEIGHT', 'sum'),\n",
    "    total_net_wgt_after=('NET WEIGHT AFTER DRYING', 'sum'),\n",
    "    total_net_wgt_before_kg=('NET WEIGHT', lambda x: x.sum() / 1000),\n",
    "    total_net_wgt_after_kg=('NET WEIGHT AFTER DRYING', lambda x: x.sum() / 1000),\n",
    "    avg_kor_before=('ARRIV KOR', 'mean'),\n",
    "    avg_kor_after=('KOR AFTER DRYING', 'mean'),\n",
    "    avg_moisture_before=('MOISTURE %', 'mean'),\n",
    "    avg_moisture_after=('MOISTURE % AFTER DRYING', 'mean'),\n",
    "    total_weight_loss_or_gain=('WEIGHT LOSS OR GAIN', 'sum'),\n",
    "    avg_cycle_time=('CYCLE TIME (DAYS)', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "# Print monthly summary in table format\n",
    "print(\"\\nMonthly Summary:\")\n",
    "print(tabulate(monthly_summary, headers=\"keys\", tablefmt=\"pretty\", showindex=False))\n",
    "\n",
    "# Station Summary\n",
    "station_summary = drying_df.groupby('Station').agg(\n",
    "    total_net_wgt_before=('NET WEIGHT', 'sum'),\n",
    "    total_net_wgt_after=('NET WEIGHT AFTER DRYING', 'sum'),\n",
    "    total_net_wgt_before_kg=('NET WEIGHT', lambda x: x.sum() / 1000),\n",
    "    total_net_wgt_after_kg=('NET WEIGHT AFTER DRYING', lambda x: x.sum() / 1000),\n",
    "    avg_kor_before=('ARRIV KOR', 'mean'),\n",
    "    avg_kor_after=('KOR AFTER DRYING', 'mean'),\n",
    "    avg_moisture_before=('MOISTURE %', 'mean'),\n",
    "    avg_moisture_after=('MOISTURE % AFTER DRYING', 'mean'),\n",
    "    total_weight_loss_or_gain=('WEIGHT LOSS OR GAIN', 'sum'),\n",
    "    avg_cycle_time=('CYCLE TIME (DAYS)', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "# Print station summary in table format\n",
    "print(\"\\nStation Summary:\")\n",
    "print(tabulate(station_summary, headers=\"keys\", tablefmt=\"pretty\", showindex=False))\n",
    "\n",
    "# Today's Purchases (for the previous day)\n",
    "yesterday = pd.to_datetime('today') - pd.Timedelta(days=1)\n",
    "today_purchases = drying_df[drying_df['DATE'] == yesterday]\n",
    "\n",
    "# Summary for Today's Purchases\n",
    "today_summary = {\n",
    "    \"Total Net Weight Before Drying\": today_purchases['NET WEIGHT'].sum(),\n",
    "    \"Total Net Weight After Drying\": today_purchases['NET WEIGHT AFTER DRYING'].sum(),\n",
    "    \"Average KOR Before Drying\": today_purchases['ARRIV KOR'].mean(),\n",
    "    \"Average KOR After Drying\": today_purchases['KOR AFTER DRYING'].mean(),\n",
    "    \"Average Moisture Before Drying\": today_purchases['MOISTURE %'].mean(),\n",
    "    \"Average Moisture After Drying\": today_purchases['MOISTURE % AFTER DRYING'].mean(),\n",
    "    \"Total Weight Loss or Gain\": today_purchases['WEIGHT LOSS OR GAIN'].sum(),\n",
    "    \"Average Cycle Time (Days)\": today_purchases['CYCLE TIME (DAYS)'].mean()\n",
    "}\n",
    "\n",
    "# Convert today's summary to DataFrame for better visualization in table format\n",
    "today_summary_df = pd.DataFrame([today_summary])\n",
    "\n",
    "# Print today's summary in table format\n",
    "print(\"\\nToday's Drying Summary:\")\n",
    "print(tabulate(today_summary_df, headers=\"keys\", tablefmt=\"pretty\", showindex=False))\n",
    "\n",
    "# Save all summaries to Excel\n",
    "with pd.ExcelWriter('drying_summary_stats.xlsx') as writer:\n",
    "    monthly_summary.to_excel(writer, sheet_name='Monthly Summary', index=False)\n",
    "    station_summary.to_excel(writer, sheet_name='Station Summary', index=False)\n",
    "    today_summary_df.to_excel(writer, sheet_name='Today Summary', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465d7878-0b44-4cf6-b73e-d90362d7d69e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2f4101-accf-4d18-a9fd-2b4850e49d3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5191012b-6dda-440c-a8c0-a594328cf5c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d804a4-0878-41ea-a77a-6539120a67ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c5240e-1ce8-4406-87f9-1763457d73ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a580c565-a650-466e-b8a4-90fbf0fbda04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcaef8f-9679-4eb9-90f9-7cbb40ca4b46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eea1e36-aac5-4305-82ba-044ecbc62de7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9b4e60-aceb-4aff-af86-eb5aa4433e21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086d7681-c971-47ab-92c2-93a5389239ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1130e7-68e9-48b2-bd4b-122f2842de2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a228c5-3fa4-4c17-9862-264e86e0074e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d1f16f-e25a-41db-a0cc-e8acccc08dc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df730bf9-a8e5-4546-8f7a-9d61b09ef7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common columns across all drying sheets:\n",
      "{'# OF BAGS AFTER DRYING', 'NET WEIGHT AFTER DRYING', 'ARRIV KOR', 'NET WEIGHT', 'KOR AFTER DRYING', 'GRN #', 'WEIGHT LOSS(Kg)', '# OF BAGS', 'MOISTURE %', 'DATE AFTER DRYING', 'MOISTURE % AFTER DRYING', 'LOSS %AGE', 'DATE'}\n"
     ]
    }
   ],
   "source": [
    "# Get the column names from each DataFrame\n",
    "sampa_columns = set(sampa_df.columns)\n",
    "nkrankwanta_columns = set(nkrankwanta_df.columns)\n",
    "drobo_columns = set(drobo_df.columns)\n",
    "wenchi_columns = set(wenchi_df.columns)\n",
    "techiman_columns = set(techiman_df.columns)\n",
    "sawla_columns = set(sawla_df.columns)\n",
    "\n",
    "# Find the intersection (common columns) across all the DataFrames\n",
    "common_columns = sampa_columns.intersection(nkrankwanta_columns, drobo_columns, wenchi_columns, techiman_columns, sawla_columns)\n",
    "\n",
    "# Display the common columns\n",
    "print(\"Common columns across all drying sheets:\")\n",
    "print(common_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c44f222-3279-4e08-96e5-1df1bfb136c6",
   "metadata": {},
   "source": [
    "#### Append all drying sheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b60e2497-1413-4825-b48e-583674bd627e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 13)\n"
     ]
    }
   ],
   "source": [
    "# Convert common_columns to a list\n",
    "common_columns_list = list(common_columns)\n",
    "\n",
    "# Append the DataFrames with only common columns\n",
    "drying_df = pd.concat([df[common_columns_list] for df in [sampa_df, nkrankwanta_df, drobo_df, wenchi_df, techiman_df, sawla_df]], ignore_index=True)\n",
    "\n",
    "# Display the shape of the combined DataFrame\n",
    "print(drying_df.shape)\n",
    "\n",
    "# Save the final combined DataFrame to an Excel file\n",
    "drying_df.to_excel('combined_drying_data.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a5a5882-1052-4ccf-918b-60256b037868",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['INPUT FOR DRYING', 'Unnamed: 1', 'Unnamed: 2', 'Unnamed: 3',\n",
      "       'Unnamed: 4', 'Unnamed: 5', 'OUTPUT AFTER DRYING', 'Unnamed: 7',\n",
      "       'Unnamed: 8', 'Unnamed: 9', 'Unnamed: 10', 'Unnamed: 11', 'Unnamed: 12',\n",
      "       'Unnamed: 13'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Check the columns of the first sheet (for example, 'SAMPA-DRYING')\n",
    "print(selected_sheets['SAMPA-DRYING'].columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf57f260-1a7e-49aa-a22a-b8053aded403",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce51e8e-5dd0-4c5a-ba61-07f8aad125e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63be385-4a71-42ab-b3ae-14ca0674398a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54eec48-d4a2-4943-9e98-9462cda5429e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b0beb89-682a-40ba-a1b7-d41a3d01a917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Station Column based on the sheet name\n",
    "station_mapping = {\n",
    "    'SAMPA-DRYING': 'Sampa',\n",
    "    'NKRANKWANTA-DRYING': 'Nkrankwanta',\n",
    "    'DROBO-DRYING': 'Drobo',\n",
    "    'WENCHI-DRYING': 'Wenchi',\n",
    "    'TECHIMAN-DRYING': 'Techiman',\n",
    "    'SAWLA-DRYING': 'Sawla'\n",
    "}\n",
    "\n",
    "# Adding the 'Station' column to each DataFrame\n",
    "for sheet_name, df in selected_sheets.items():\n",
    "    df['Station'] = station_mapping.get(sheet_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8febb18-4850-4a69-87d1-16bdd151619a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SUMMARY', '2025-QUALITY REP', 'FUNDING', 'SAMPA-PURCHASES', 'SAMPA-DRYING', 'SAMPA-DISPATCHES ', 'SAMPA W.H', 'NKRANKWANTA-PURCHASES', 'NKRANKWANTA-DRYING', 'NKRANKWANTA-DISPATCHES', 'NKRANKWANTA W.H', 'DROBO-PURCHASES', 'DROBO-DRYING', 'DROBO-DISPATCHES', 'DROBO W.H', 'WENCHI-PURCHASES', 'WENCHI-DRYING', 'WENCHI-DISPATCHES', 'WENCHI W.H', 'TECHIMAN-PURCHASES', 'TECHIMAN-DRYING', 'TECHIMAN-DISPATCHES', 'TECHIMAN W.H', 'SAWLA-PURCHASES', 'SAWLA-DRYING', 'SAWLA-DISPATCHES', 'SAWLA W.H ', 'LUC DISP', 'EX-TEMA', 'TOTALS', 'Comparisons']\n"
     ]
    }
   ],
   "source": [
    "# Loading drying workbook\n",
    "xls_drying = pd.ExcelFile('GHANA ORIGIN REP.xlsx')\n",
    "\n",
    "# Display sheet names to check the structure\n",
    "print(xls_drying.sheet_names)\n",
    "\n",
    "# Example: Create DataFrames for each drying sheet\n",
    "sampa_drying_df = pd.read_excel(xls_drying, sheet_name='SAMPA-DRYING', header=1)\n",
    "nkrankwanta_drying_df = pd.read_excel(xls_drying, sheet_name='NKRANKWANTA-DRYING', header=1)\n",
    "drobo_drying_df = pd.read_excel(xls_drying, sheet_name='DROBO-DRYING', header=1)\n",
    "wenchi_drying_df = pd.read_excel(xls_drying, sheet_name='WENCHI-DRYING', header=1)\n",
    "techiman_drying_df = pd.read_excel(xls_drying, sheet_name='TECHIMAN-DRYING', header=1)\n",
    "sawla_drying_df = pd.read_excel(xls_drying, sheet_name='SAWLA-DRYING', header=1)\n",
    "\n",
    "# Adding Station Column for each DataFrame\n",
    "sampa_drying_df['Station'] = 'Sampa'\n",
    "nkrankwanta_drying_df['Station'] = 'Nkrankwanta'\n",
    "drobo_drying_df['Station'] = 'Drobo'\n",
    "wenchi_drying_df['Station'] = 'Wenchi'\n",
    "techiman_drying_df['Station'] = 'Techiman'\n",
    "sawla_drying_df['Station'] = 'Sawla'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1168fd5-a206-49c6-939b-8a01386967f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "      <th>1144</th>\n",
       "      <th>96123.05</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>1174</th>\n",
       "      <th>95178.3</th>\n",
       "      <th>0</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "      <th>916.75</th>\n",
       "      <th>0.9537254591900693</th>\n",
       "      <th>Unnamed: 13</th>\n",
       "      <th>Unnamed: 14</th>\n",
       "      <th>Station</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DATE</td>\n",
       "      <td>GRN #</td>\n",
       "      <td># OF BAGS</td>\n",
       "      <td>NET WEIGHT</td>\n",
       "      <td>ARRIV KOR</td>\n",
       "      <td>MOISTURE %</td>\n",
       "      <td>DATE</td>\n",
       "      <td># OF BAGS</td>\n",
       "      <td>NET WEIGHT</td>\n",
       "      <td>KOR AFTER DRYING</td>\n",
       "      <td>MOISTURE %</td>\n",
       "      <td>WEIGHT LOSS(Kg)</td>\n",
       "      <td>LOSS %AGE</td>\n",
       "      <td>Pickings-Kgs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Techiman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-01-13 00:00:00</td>\n",
       "      <td>151</td>\n",
       "      <td>24</td>\n",
       "      <td>2036</td>\n",
       "      <td>0</td>\n",
       "      <td>11.9</td>\n",
       "      <td>14-01-2025</td>\n",
       "      <td>24</td>\n",
       "      <td>1999.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.3</td>\n",
       "      <td>36.8</td>\n",
       "      <td>1.807466</td>\n",
       "      <td>NaN</td>\n",
       "      <td>212.0</td>\n",
       "      <td>Techiman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-01-13 00:00:00</td>\n",
       "      <td>152</td>\n",
       "      <td>23</td>\n",
       "      <td>1957</td>\n",
       "      <td>0</td>\n",
       "      <td>11.9</td>\n",
       "      <td>14-01-2025</td>\n",
       "      <td>24</td>\n",
       "      <td>1926</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.6</td>\n",
       "      <td>31</td>\n",
       "      <td>1.584057</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69.0</td>\n",
       "      <td>Techiman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-01-14 00:00:00</td>\n",
       "      <td>153</td>\n",
       "      <td>8</td>\n",
       "      <td>692</td>\n",
       "      <td>0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>15-01-25</td>\n",
       "      <td>8</td>\n",
       "      <td>673.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.2</td>\n",
       "      <td>18.9</td>\n",
       "      <td>2.731214</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.0</td>\n",
       "      <td>Techiman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-01-14 00:00:00</td>\n",
       "      <td>154</td>\n",
       "      <td>48</td>\n",
       "      <td>3840</td>\n",
       "      <td>0</td>\n",
       "      <td>12.7</td>\n",
       "      <td>15-01-25</td>\n",
       "      <td>47</td>\n",
       "      <td>3768.65</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.3</td>\n",
       "      <td>71.35</td>\n",
       "      <td>1.858073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Techiman</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Unnamed: 0 Unnamed: 1       1144    96123.05 Unnamed: 4  \\\n",
       "0                 DATE      GRN #  # OF BAGS  NET WEIGHT  ARRIV KOR   \n",
       "1  2025-01-13 00:00:00        151         24        2036          0   \n",
       "2  2025-01-13 00:00:00        152         23        1957          0   \n",
       "3  2025-01-14 00:00:00        153          8         692          0   \n",
       "4  2025-01-14 00:00:00        154         48        3840          0   \n",
       "\n",
       "   Unnamed: 5  Unnamed: 6       1174     95178.3                 0  \\\n",
       "0  MOISTURE %        DATE  # OF BAGS  NET WEIGHT  KOR AFTER DRYING   \n",
       "1        11.9  14-01-2025         24      1999.2               NaN   \n",
       "2        11.9  14-01-2025         24        1926               NaN   \n",
       "3        10.4    15-01-25          8       673.1               NaN   \n",
       "4        12.7    15-01-25         47     3768.65               NaN   \n",
       "\n",
       "  Unnamed: 10           916.75 0.9537254591900693   Unnamed: 13  Unnamed: 14  \\\n",
       "0  MOISTURE %  WEIGHT LOSS(Kg)          LOSS %AGE  Pickings-Kgs          NaN   \n",
       "1         9.3             36.8           1.807466           NaN        212.0   \n",
       "2         9.6               31           1.584057           NaN         69.0   \n",
       "3         9.2             18.9           2.731214           NaN         28.0   \n",
       "4         9.3            71.35           1.858073           NaN          NaN   \n",
       "\n",
       "    Station  \n",
       "0  Techiman  \n",
       "1  Techiman  \n",
       "2  Techiman  \n",
       "3  Techiman  \n",
       "4  Techiman  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "techiman_drying_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c0036b-a62a-4e4d-b2d9-5d95a7d39c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to keep for drying data\n",
    "columns_to_keep = ['DATE', 'GRN #', '# OF BAGS', 'NET WEIGHT', 'ARRIV KOR', 'MOISTURE %', \n",
    "                   'DATE', '# OF BAGS', 'NET WEIGHT', 'KOR AFTER DRYING', 'MOISTURE %', \n",
    "                   'WEIGHT LOSS(Kg)', 'LOSS %AGE', 'Pickings-Kgs', 'Station']\n",
    "\n",
    "# Apply to each DataFrame\n",
    "sampa_drying_df = sampa_drying_df[columns_to_keep]\n",
    "nkrankwanta_drying_df = nkrankwanta_drying_df[columns_to_keep]\n",
    "drobo_drying_df = drobo_drying_df[columns_to_keep]\n",
    "wenchi_drying_df = wenchi_drying_df[columns_to_keep]\n",
    "techiman_drying_df = techiman_drying_df[columns_to_keep]\n",
    "sawla_drying_df = sawla_drying_df[columns_to_keep]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec116c6-7652-4689-8732-e053d956873f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
